{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   defect_id          1000 non-null   int64  \n",
      " 1   product_id         1000 non-null   int64  \n",
      " 2   defect_type        1000 non-null   object \n",
      " 3   defect_date        1000 non-null   object \n",
      " 4   defect_location    1000 non-null   object \n",
      " 5   severity           1000 non-null   object \n",
      " 6   inspection_method  1000 non-null   object \n",
      " 7   repair_cost        1000 non-null   float64\n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 62.6+ KB\n",
      "None\n",
      "No missing values detected in the dataset.\n",
      "  defect_type defect_date defect_location  severity  inspection_method  \\\n",
      "0  Structural    6/6/2024       Component         1  Visual Inspection   \n",
      "1  Functional   4/26/2024       Component         1  Visual Inspection   \n",
      "2  Structural   2/15/2024        Internal         1  Automated Testing   \n",
      "3  Functional   3/28/2024        Internal         0  Automated Testing   \n",
      "4    Cosmetic   4/26/2024       Component         1     Manual Testing   \n",
      "\n",
      "   repair_cost  \n",
      "0       245.47  \n",
      "1        26.87  \n",
      "2       835.81  \n",
      "3       444.47  \n",
      "4       823.64  \n",
      "Preprocessing complete. Data is ready for modeling!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')  # Ignoring warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"defects_data.csv\")\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(df.info())\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "if missing_values.any():\n",
    "    print(\"Missing values detected in the dataset:\")\n",
    "    print(missing_values)\n",
    "    \n",
    "    # Fill missing values with the mean of each column\n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "    print(\"Missing values have been filled with column means.\")\n",
    "else:\n",
    "    print(\"No missing values detected in the dataset.\")\n",
    "\n",
    "# Drop irrelevant columns\n",
    "df = df.drop(columns=['defect_id', 'product_id'])\n",
    "\n",
    "# Encode categorical target variable\n",
    "label_encoder = LabelEncoder()\n",
    "df['severity'] = label_encoder.fit_transform(df['severity'])\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['severity'])\n",
    "y = df['severity']\n",
    "\n",
    "# Define categorical and numerical features\n",
    "categorical_features = ['defect_type', 'defect_date', 'defect_location', 'inspection_method']\n",
    "numerical_features = ['repair_cost']\n",
    "\n",
    "# Apply One-Hot Encoding to categorical features and scale numerical features\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    ('scaler', StandardScaler(), numerical_features)\n",
    "])\n",
    "\n",
    "X_transformed = column_transformer.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "print(\"Preprocessing complete. Data is ready for modeling!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0000\n",
      "Validation Accuracy (Cross-Validation Mean): 0.3263\n",
      "Validation Accuracy Std Dev: 0.0286\n",
      "R² Score on Test Data: 0.3000\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0000\n",
      "Validation Accuracy (Cross-Validation Mean): 0.3263\n",
      "Validation Accuracy Std Dev: 0.0286\n",
      "R² Score on Test Data: 0.3000\n"
     ]
    }
   ],
   "source": [
    "# Re-import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Train Random Forest Model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Training Accuracy\n",
    "train_accuracy = rf_model.score(X_train, y_train)\n",
    "\n",
    "# Evaluate model using cross-validation\n",
    "cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Calculate R-squared on test data\n",
    "r_squared = rf_model.score(X_test, y_test)\n",
    "\n",
    "# Display results\n",
    "cv_scores_mean = np.mean(cv_scores)\n",
    "cv_scores_std = np.std(cv_scores)\n",
    "\n",
    "# Print out results\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Validation Accuracy (Cross-Validation Mean): {cv_scores_mean:.4f}\")\n",
    "print(f\"Validation Accuracy Std Dev: {cv_scores_std:.4f}\")\n",
    "print(f\"R² Score on Test Data: {r_squared:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "Best Parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Training Accuracy: 0.6250\n",
      "Validation Accuracy (Cross-Validation Mean): 0.3563\n",
      "Validation Accuracy Std Dev: 0.0326\n",
      "R² Score on Test Data: 0.3400\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "# Define parameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of trees\n",
    "    'max_depth': [10, 20, None],  # Tree depth\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum samples required to split\n",
    "    'min_samples_leaf': [1, 2, 5],  # Minimum samples required at a leaf\n",
    "    'max_features': ['sqrt', 'log2'],  # Consider subset of features\n",
    "}\n",
    "\n",
    "# Perform Grid Search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "# Train with best hyperparameters\n",
    "rf_model = RandomForestClassifier(**best_params, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Training Accuracy\n",
    "train_accuracy = rf_model.score(X_train, y_train)\n",
    "\n",
    "# Evaluate model using cross-validation\n",
    "cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Calculate R² on test data\n",
    "r_squared = rf_model.score(X_test, y_test)\n",
    "\n",
    "# Display results\n",
    "cv_scores_mean = np.mean(cv_scores)\n",
    "cv_scores_std = np.std(cv_scores)\n",
    "\n",
    "# Print out results\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Validation Accuracy (Cross-Validation Mean): {cv_scores_mean:.4f}\")\n",
    "print(f\"Validation Accuracy Std Dev: {cv_scores_std:.4f}\")\n",
    "print(f\"R² Score on Test Data: {r_squared:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
